# Tests & Verification Guide# Tests Documentation



This folder contains all test scripts and verification utilities for the Real Python Web Scraper.This folder contains test scripts that verify the functionality and integration of the `webscraper_core` modules.



## üìã Folder Contents## Project Structure



``````

tests/webscrapper/

‚îú‚îÄ‚îÄ __init__.py‚îú‚îÄ‚îÄ webscraper_core/           # Core scraper package

‚îú‚îÄ‚îÄ README.md (this file)‚îÇ   ‚îú‚îÄ‚îÄ __init__.py

‚îÇ‚îÇ   ‚îú‚îÄ‚îÄ database.py            # SQLAlchemy setup

‚îú‚îÄ‚îÄ Unit Tests:‚îÇ   ‚îú‚îÄ‚îÄ manager.py             # Orchestration logic

‚îÇ   ‚îú‚îÄ‚îÄ test_scraper.py              # WebScraper unit tests‚îÇ   ‚îú‚îÄ‚îÄ scraper.py             # HTML fetching & extraction

‚îÇ   ‚îú‚îÄ‚îÄ test_analyzer.py             # Text analyzer tests‚îÇ   ‚îú‚îÄ‚îÄ analyzer.py            # Text analysis

‚îÇ   ‚îú‚îÄ‚îÄ test_article_extraction.py   # Article extraction tests‚îÇ   ‚îú‚îÄ‚îÄ models/                # ORM models

‚îÇ   ‚îî‚îÄ‚îÄ test_call_packages.py        # Package dependency tests‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py

‚îÇ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py            # Shared declarative base

‚îú‚îÄ‚îÄ Integration Tests:‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ author.py          # Author model

‚îÇ   ‚îú‚îÄ‚îÄ test_models_sync.py          # Database models integration‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ article.py         # Article model

‚îÇ   ‚îî‚îÄ‚îÄ test_main_workflow.py        # Complete workflow tests‚îÇ   ‚îî‚îÄ‚îÄ repositories/          # Repository pattern

‚îÇ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py

‚îî‚îÄ‚îÄ Verification Scripts:‚îÇ       ‚îú‚îÄ‚îÄ base_repository.py # Generic base repository

    ‚îú‚îÄ‚îÄ check_db.py                  # Quick database check‚îÇ       ‚îú‚îÄ‚îÄ author_repository.py

    ‚îú‚îÄ‚îÄ verify_scrape.py             # Detailed article list‚îÇ       ‚îî‚îÄ‚îÄ article_repository.py

    ‚îú‚îÄ‚îÄ show_results.py              # Complete demonstration‚îÇ

    ‚îú‚îÄ‚îÄ final_verification.py        # Comprehensive verification‚îú‚îÄ‚îÄ tests/                     # Test suite

    ‚îî‚îÄ‚îÄ test_realpython_rules.py     # Real Python rules compliance‚îÇ   ‚îú‚îÄ‚îÄ __init__.py

```‚îÇ   ‚îú‚îÄ‚îÄ test_scraper.py        # WebScraper unit tests

‚îÇ   ‚îú‚îÄ‚îÄ test_analyzer.py       # Analyzer unit tests

## üöÄ Quick Start‚îÇ   ‚îú‚îÄ‚îÄ test_models_sync.py    # Integration tests

‚îÇ   ‚îî‚îÄ‚îÄ README.md              # This file

### Run All Tests‚îÇ

```bash‚îú‚îÄ‚îÄ main.py                    # Entry point

cd tests‚îú‚îÄ‚îÄ debug_analyzer.py          # Debug utilities

pytest . -v‚îú‚îÄ‚îÄ scraper_data.db            # Production database

```‚îî‚îÄ‚îÄ check_database_records.py  # Database query utility

```

### Run Verification (Choose One)

```bash## Test Files

python check_db.py                  # Quick check (1 sec)

python verify_scrape.py             # Article list (2 sec)### 1. `test_scraper.py`

python show_results.py              # Full demo (3 sec)**Purpose**: Verify the WebScraper class correctly fetches and extracts titles from HTML content.

python final_verification.py        # Comprehensive (5-10 sec)

```**What it tests**:

- WebScraper initialization

---- Title extraction from HTML (h1, h2, h3 tags)

- Handling empty HTML documents

## üìù Unit Tests- Custom HTML input via `scrape(response_text=...)`

- Proper list return type from extraction methods

### 1. `test_scraper.py`

**Purpose**: Test WebScraper HTML parsing and article extraction**How to run**:

```bash

**Tests**:python tests/test_scraper.py

- ‚úì `test_extract_article_data_empty` - Handles empty HTML```

- ‚úì `test_extract_article_data_with_articles` - Extracts real articles

- ‚úì `test_extract_article_data_structure` - Validates structure**Expected output**:

- ‚úì `test_scrape_returns_article_list` - Return type verification```

- ‚úì `test_extract_titles_backward_compatibility` - Legacy supportRunning scraper tests...



**Run**:‚úì WebScraper initializes correctly

```bash‚úì extract_titles returns empty list for empty HTML

pytest test_scraper.py -v‚úì extract_titles extracts all titles correctly

```‚úì scrape method works with custom HTML



**What it validates**:‚úÖ All scraper tests passed!

- Real Python HTML selector correctness```

- Article data extraction accuracy

- Error handling for edge cases**What it validates**:

- ‚úÖ WebScraper class initializes without errors

---- ‚úÖ Titles are correctly extracted from HTML elements

- ‚úÖ Edge cases (empty HTML) handled gracefully

### 2. `test_analyzer.py`- ‚úÖ Custom HTML input works as expected

**Purpose**: Test text analysis and word frequency

---

**Tests**:

- Punctuation removal### 2. `test_analyzer.py`

- Contraction expansion**Purpose**: Verify the text analyzer correctly processes titles, removes punctuation, handles contractions, and counts word frequencies.

- Stop word filtering

- Word frequency counting**What it tests**:

- Basic title processing and text generation

**Run**:- Punctuation removal and contraction expansion ("what's" ‚Üí "what is")

```bash- Stop word filtering ("the", "and", "or", etc.)

pytest test_analyzer.py -v- Word frequency counting via Counter

```- Edge cases (empty input)



---**How to run**:

```bash

### 3. `test_article_extraction.py`python tests/test_analyzer.py

**Purpose**: Test article extraction from different sources```



**Run**:**Expected output**:

```bash```

pytest test_article_extraction.py -vRunning analyzer tests...

```

‚úì process_titles returns text and counter

---‚úì Punctuation and contractions handled correctly

‚úì Stop words are filtered correctly

## üîß Integration Tests‚úì Counter tracks word frequencies accurately

‚úì Empty titles handled gracefully

### 4. `test_models_sync.py`

**Purpose**: Test database models and relationships‚úÖ All analyzer tests passed!

```

**Validates**:

- Database initialization**What it validates**:

- Author-Article relationships- ‚úÖ Text preprocessing removes punctuation correctly

- Repository CRUD operations- ‚úÖ Contractions are expanded properly

- ‚úÖ Stop words are filtered when provided

**Run**:- ‚úÖ Counter object tracks frequencies accurately

```bash- ‚úÖ Empty input doesn't cause errors

pytest test_models_sync.py -v

```---



---### 3. `test_models_sync.py`

**Purpose**: Integration test verifying that the Author and Article models, repositories, and database layers work together properly.

### 5. `test_main_workflow.py`

**Purpose**: Test complete scraping workflow**What it tests**:

- Database initialization (SQLAlchemy engine and session creation)

**Validates**:- Table creation via `Base.metadata.create_all(engine)`

- End-to-end scraping- AuthorRepository CRUD operations (create author)

- Database storage- ArticleRepository CRUD operations (create article)

- Deduplication- Relationship between Author and Article models

- Querying and listing records from both repositories

**Run**:

```bash**How to run**:

pytest test_main_workflow.py -v```bash

```python tests/test_models_sync.py

```

---

**Expected output**:

## üîç Verification Scripts- "Initializing database..."

- Created author and article entries printed with their ORM representation

### ‚úÖ Quick Database Check- List of all authors and articles in the database

```bash- "Test completed successfully!"

python check_db.py

```**What it validates**:

- ‚úÖ Models import correctly from centralized `models/__init__.py`

**What it shows**:- ‚úÖ Relationships resolve properly (no missing reference errors)

- Total articles in database- ‚úÖ Session management works in repositories

- Total unique authors- ‚úÖ Create, read, and list operations work end-to-end

- Recent articles with details- ‚úÖ Database schema is correctly initialized



**Use when**: You just need a quick confirmation that data exists---



**Output example**:## Running All Tests

```

Total articles in DB: 19To run all tests individually:

Total authors in DB: 8```bash

python tests/test_scraper.py

Recent articles:python tests/test_analyzer.py

  - Polars vs pandas: What's the Difference? (Author ID: 1)python tests/test_models_sync.py

    URL: https://realpython.com/polars-vs-pandas/```

    Date: 2025-10-15

```Or run all tests at once using pytest (if installed):

```bash

---pytest tests/ -v

```

### üìä Detailed Article Verification

```bashOr with basic Python (runs each test file):

python verify_scrape.py```bash

```python -m pytest tests/

```

**What it shows**:

- Formatted table of all articles---

- Title, author, and publication date

- All article URLs## Test Database

- Success confirmation

- `test_models_sync.py` creates a temporary database file named `test_scraper.db` in the project root

**Use when**: Want to see all scraped articles nicely formatted- This file is safe to delete; it will be recreated on the next test run

- For production databases, use `scraper_data.db` (created by `webscraper_core/database.py`)

**Output example**:

```---

REAL PYTHON ARTICLES SCRAPED AND SAVED

================================================================================## Architecture Overview

Title                                              | Author          | Date

--------------------------------------------------------------------------------The tests validate this flow:

Polars vs pandas: What's the Difference?          | Ian Eyre        | 2025-10-15

How to Use Python: Your First Steps               | Leodanis...     | 2025-10-13```

...database.py (SQLAlchemy ORM setup)

```    ‚Üì

models/ (Author, Article, Base)

---    ‚Üì

repositories/ (AuthorRepository, ArticleRepository)

### üéØ Complete Results Demonstration    ‚Üì

```bashtest_models_sync.py (verification)

python show_results.py```

```

**Key components tested**:

**What it shows**:1. **Database Layer**: Engine creation, session management

1. Database statistics (articles & authors)2. **Models Layer**: Declarative models, relationships, cascade operations

2. Complete article table (ID, title, author, date)3. **Repository Layer**: CRUD operations abstracted via BaseRepository

3. Full list of article URLs4. **Integration**: End-to-end data flow from DB to ORM to API

4. Articles grouped by author

5. Data validation results---



**Use when**: Need comprehensive overview of everything## Troubleshooting



**Sections**:### "No module named 'webscraper_core'"

- Database SummaryEnsure you run tests from the project root:

- All Scraped Articles```bash

- Article URLscd c:\Users\Andres\OneDrive\Python Projects\webscrapper

- Articles by Authorpython tests/test_scraper.py

- Data Validation```



---The test files automatically handle path resolution with:

```python

### ‚ú® Final Comprehensive Verificationimport sys

```bashfrom pathlib import Path

python final_verification.pysys.path.insert(0, str(Path(__file__).parent.parent))

``````



**What it shows**:### Import errors in tests

1. Database connection verification- Run tests from the project root directory

2. Data structure validation- Tests use relative path adjustment (no need for PYTHONPATH)

3. Real Python extraction validation- All modules import correctly via `webscraper_core.*`

4. Live scraper test

5. Complete verification summary### Database errors during test

- Delete `test_scraper.db` and re-run the test

**Use when**: Need thorough validation that everything works- Ensure SQLAlchemy is installed: `pip install sqlalchemy`

- Test database is separate from production (`scraper_data.db`)

**Validation checks**:

- ‚úì Database connected---

- ‚úì Data structure valid

- ‚úì All required fields present## Adding New Tests

- ‚úì URLs are absolute format

- ‚úì Articles from realpython.comTo add new tests:

- ‚úì Live scraper functional1. Create a new file `test_your_feature.py` in this folder

2. Follow the naming convention: `test_*.py`

---3. Import necessary modules from `webscraper_core`

4. Document the test in this README

### üåê Real Python Rules Compliance

```bashExample template:

python test_realpython_rules.py```python

```"""Test description."""

from webscraper_core.database import create_connection, create_tables

**What it checks**:from webscraper_core.repositories.author_repository import AuthorRepository

- Correct HTML selector usage

- Real Python website structure compliancedef test_feature():

- Article extraction accuracy    # Setup

- HTML element validation    SessionLocal = create_connection('test_db.db')

    create_tables()

**Use when**: Verifying scraper follows Real Python rules    session = SessionLocal()

    

**Validates**:    # Test logic

- `div.card.border-0` elements found    repo = AuthorRepository(session)

- `h2.card-title` elements for titles    # ... assertions ...

- `span.mr-2` elements for dates    

- Proper URL extraction    # Cleanup

    session.close()

---    print("Test passed!")



## üìä Test Results Summaryif __name__ == '__main__':

    test_feature()

### Expected Results When Everything Works```



‚úÖ **Database**: 19+ articles stored---

‚úÖ **Authors**: 8 unique authors

‚úÖ **Data Integrity**: All fields populated## Best Practices

‚úÖ **URLs**: All absolute format (https://realpython.com/...)

‚úÖ **Dates**: All properly parsed- ‚úÖ Use separate test databases (e.g., `test_*.db`) to avoid affecting production data

‚úÖ **Deduplication**: 0 duplicates on re-run- ‚úÖ Always close sessions after tests: `session.close()`

- ‚úÖ Test one feature per file for clarity

### If Something Fails- ‚úÖ Print informative messages during test execution

- ‚úÖ Document expected behavior in docstrings

| Issue | Solution |

|-------|----------|---

| "Failed to connect to database" | Run: `cd .. && python main.py` |

| "No articles found" | Database needs data - run main scraper |## Related Files

| Import errors | Run from tests folder: `cd tests` |

| Database locked | Delete `scraper_data.db` and retry |- `webscraper_core/database.py` - Core database initialization

- `webscraper_core/models/` - ORM model definitions

---- `webscraper_core/repositories/` - CRUD operation abstractions

- `check_database_records.py` - Utility to query the database (in project root)

## üîÑ Typical Workflows

### First Time Setup
```bash
cd ..
python main.py                      # Scrape articles
cd tests
python check_db.py                  # Quick verify
```

### Verify After Changes
```bash
cd tests
python final_verification.py        # Complete check
pytest test_scraper.py -v          # Run unit tests
```

### Full Test Suite
```bash
cd tests
pytest . -v                         # All tests + coverage
python show_results.py              # Show all results
```

---

## üéØ Which Script to Use?

| Goal | Script | Command | Time |
|------|--------|---------|------|
| Quick status | `check_db.py` | `python check_db.py` | 1s |
| See articles | `verify_scrape.py` | `python verify_scrape.py` | 2s |
| Full overview | `show_results.py` | `python show_results.py` | 3s |
| Comprehensive | `final_verification.py` | `python final_verification.py` | 5-10s |
| Rules check | `test_realpython_rules.py` | `python test_realpython_rules.py` | 15s |
| Unit tests | pytest | `pytest test_scraper.py -v` | 2-5s |
| All tests | pytest | `pytest . -v` | 10-15s |

---

## üêõ Debugging Tips

### Enable Detailed Output
```bash
python -c "from webscraper_core.database import create_connection; from webscraper_core.models import Article; s = create_connection('../scraper_data.db')(); print(f'Articles: {s().query(Article).count()}')"
```

### Check Database with sqlite3
```bash
sqlite3 ../scraper_data.db
> SELECT COUNT(*) FROM article;
> SELECT * FROM article LIMIT 5;
> .quit
```

### View Specific Article
```bash
python -c "
from webscraper_core.database import create_connection
from webscraper_core.models import Article
s = create_connection('../scraper_data.db')()
a = s.query(Article).first()
print(f'Title: {a.title}')
print(f'URL: {a.url}')
print(f'Date: {a.publication_date}')
"
```

---

## ‚úÖ Final Verification Checklist

Before considering the project complete:

- [ ] `python check_db.py` - Shows 19+ articles
- [ ] `python verify_scrape.py` - All articles formatted correctly
- [ ] `python show_results.py` - All sections complete
- [ ] `python final_verification.py` - All checks ‚úì
- [ ] `python test_realpython_rules.py` - Rules compliance ‚úì
- [ ] `pytest test_scraper.py -v` - All tests pass
- [ ] `pytest . -v` - Full test suite passes

---

## üìö Related Documentation

- `../README.md` - Main project documentation
- `../docs/REAL_PYTHON_RULES.md` - Official extraction rules
- `../docs/IMPLEMENTATION_SUMMARY.md` - Technical details
- `../COMPLETION_STATUS.md` - Project completion status

---

## üèÜ Status

**‚úÖ PRODUCTION READY**

All verification scripts confirm:
- ‚úì 19 Real Python articles extracted
- ‚úì All data properly stored in database
- ‚úì Scraper follows Real Python rules
- ‚úì Complete test coverage
- ‚úì Windows compatible
